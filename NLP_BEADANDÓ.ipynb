{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15T0weEApZa5MiLqNc8cgnlzq8onyhzi2",
      "authorship_tag": "ABX9TyNp8yzOzsSnVLVb9kAJrWwa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamSimion/NLP/blob/main/NLP_BEADAND%C3%93.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# News Classifier"
      ],
      "metadata": {
        "id": "P2zRCRt_4YWS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook attempts to categorize and visualize news based on their content"
      ],
      "metadata": {
        "id": "WjupPiBg4vmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installations and Imports\n",
        "\n"
      ],
      "metadata": {
        "id": "Yi01YSmY2kqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install imageio"
      ],
      "metadata": {
        "id": "YgrUTuk0NwsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import re\n",
        "import imageio"
      ],
      "metadata": {
        "id": "uc8CeDEU2tLy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Győződjünk meg róla, hogy a szükséges NLTK erőforrások letöltve vannak"
      ],
      "metadata": {
        "id": "6x-7En9K515k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "V5FDAmUF6FFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "sjhDwD0m6Pxz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset [News Dataset](https://www.kaggle.com/datasets/setseries/news-category-dataset)\n",
        "\n",
        "# **Dataset** containing categorized news articles"
      ],
      "metadata": {
        "id": "S3MShG1C6ZTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. ADAT BETÖLTÉSE"
      ],
      "metadata": {
        "id": "2gboqJzK8Rbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/My Drive/Colab Notebooks/NewsCategorizer.csv'\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(\"File loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}. Please check the file path.\")\n",
        "except pd.errors.EmptyDataError:\n",
        "    print(f\"Error: The file at {file_path} is empty.\")\n",
        "except pd.errors.ParserError:\n",
        "    print(f\"Error: Unable to parse the file at {file_path}. Check the file format.\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "ctCZJw_QOojo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/NewsCategorizer.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "zFkctY0Z6SNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Csak a 'headline' és 'category' oszlopokat tartjuk meg"
      ],
      "metadata": {
        "id": "-VGZHI8Z8aqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['headline', 'category']]\n",
        "data = data.dropna(subset=['headline'])  # Üres címek eltávolítása\n",
        "data"
      ],
      "metadata": {
        "id": "bXJ2rsBm8bpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. ELŐFELDOLGOZÁS\n",
        "\n",
        "\n",
        "*   Text lowercasing\n",
        "*   Special character removal\n",
        "*   Tokenization\n",
        "*   Stop word removing\n",
        "*   Token joining\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YwDe_DJb8ezP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "  #Text lowercasing\n",
        "    text = text.lower()\n",
        "\n",
        "  #Special character removing\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "  #Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "  #Stop word removing\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "  #Token joining\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "K8xnqN6w9NNJ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cleaned_headline'] = data['headline'].apply(lambda x: preprocess_text(str(x)))\n",
        "data"
      ],
      "metadata": {
        "id": "QUemCl999zea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Szentimentelemzés\n",
        "\n",
        "---\n",
        "\n",
        "# Egyszerű megközelítés: Használjunk egy előképzett szentimentelemző modellt / lexikont\n",
        "\n",
        ">  Pl. VADER (Valence Aware Dictionary and sEntiment Reasoner): kifejezetten alkalmas hírek elemzésére\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0iqhWAi2-WHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "def analyze_sentiment(text):\n",
        "    score = sia.polarity_scores(text)\n",
        "    if score['compound'] > 0.05:\n",
        "        return 'Positive'\n",
        "    elif score['compound'] < -0.05:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'"
      ],
      "metadata": {
        "id": "_TJS5mqpCEyU"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['sentiment'] = data['cleaned_headline'].apply(analyze_sentiment)\n",
        "data"
      ],
      "metadata": {
        "id": "VdjqXcNQCKGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. EREDMÉNYEK VIZUALIZÁLÁSA\n",
        "# Szentimentek eloszlása"
      ],
      "metadata": {
        "id": "I3x_ArMZC402"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_counts = data['sentiment'].value_counts()\n",
        "sentiment_counts.plot(kind='bar', color=['lightgray', 'lightgreen', 'salmon'], title='Sentiment Distribution')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T5xxye7eDJUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Téma szerinti szentiment eloszlás"
      ],
      "metadata": {
        "id": "XgW4zTxNDfjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_sentiment = data.groupby(['category', 'sentiment']).size().unstack(fill_value=0)\n",
        "topic_sentiment.plot(kind='bar', stacked=True, title='Sentiment by Topic', figsize=(10, 6))\n",
        "plt.xlabel('Topic')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yh7kRjIWDhFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kategóriánként százalékosan melyik mennyire pozitiv/negativ/semleges"
      ],
      "metadata": {
        "id": "eK9uA44kD54-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_sentiment_percentage = topic_sentiment.div(topic_sentiment.sum(axis=1), axis=0) * 100\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "colors = ['lightgray', 'lightgreen', 'salmon']\n",
        "\n",
        "for i, (topic, row) in enumerate(topic_sentiment_percentage.iterrows()):\n",
        "    if i < len(axes):\n",
        "        ax = axes[i]\n",
        "        ax.pie(row, labels=row.index, autopct='%1.1f%%', startangle=90, colors=colors)\n",
        "        ax.set_title(f\"***{topic}***\", fontstyle='italic', fontweight='bold')\n",
        "\n",
        "for i in range(len(topic_sentiment_percentage), len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F7HzGWDqESF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kategóriánként mely szentiment a legdominánsabb"
      ],
      "metadata": {
        "id": "kXz4lgsPSN2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def most_predominant_sentiment(df):\n",
        "    topic_sentiment = df.groupby(['category', 'sentiment']).size().unstack(fill_value=0)\n",
        "    most_predominant = topic_sentiment.idxmax(axis=1)\n",
        "    return most_predominant\n",
        "\n",
        "most_predominant = most_predominant_sentiment(data)\n",
        "\n",
        "topic_sentiment_percentage = data.groupby(['category', 'sentiment']).size().unstack(fill_value=0)\n",
        "topic_sentiment_percentage = topic_sentiment_percentage.div(topic_sentiment_percentage.sum(axis=1), axis=0) * 100\n",
        "\n",
        "category_order = topic_sentiment_percentage.index\n",
        "\n",
        "filtered_df = pd.DataFrame(columns=['category','sentiment', 'percentage'])\n",
        "\n",
        "for category in category_order:\n",
        "  sentiment = most_predominant[category]\n",
        "  percentage = topic_sentiment_percentage.loc[category, sentiment]\n",
        "  filtered_df = pd.concat([filtered_df, pd.DataFrame({'category': [category], 'sentiment': [sentiment], 'percentage': [percentage]})], ignore_index = True)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.bar(filtered_df['category'], filtered_df['percentage'], color=['lightgray' if s == 'Neutral' else 'lightgreen' if s == 'Positive' else 'salmon' for s in filtered_df['sentiment']])\n",
        "ax.set_xticklabels(filtered_df['category'], rotation=45, ha='right')\n",
        "ax.set_ylabel('Percentage %')\n",
        "ax.set_xlabel('Category')\n",
        "ax.set_title('Most Predominant Sentiment by Category')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8yWuLkfjQ2Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Mentés feldolgozott adatokkal\n"
      ],
      "metadata": {
        "id": "A0q2Y4r8Dzwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data.to_csv(\"processed_news.csv\", index=False)"
      ],
      "metadata": {
        "id": "GRAFneQJG-Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Köszönet a figyelemért  ✌"
      ],
      "metadata": {
        "id": "g6txdtyoU5Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = np.zeros((300, 500, 3), dtype=np.uint8) + 255\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(img)\n",
        "plt.text(100, 150, 'Thank you for the attention!', fontsize=30, color='purple', fontweight='bold', ha='center')\n",
        "plt.text(100, 200, '(づ｡◕‿‿◕｡)づ', fontsize=50, color='orange', ha='center')\n",
        "\n",
        "\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m-sjY1hcbYm6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}